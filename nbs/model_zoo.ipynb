{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/jordansamek/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import langdetect\n",
    "from langdetect import detect\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>35 affordable things make feel oh-so-fancy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>would die \"game thrones?\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>harry sally? john mclaine holly? quiz determin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>25 times harry styles went way make fans hella...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>penn badgley weighed wild finale \"you\" season ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         clean_title\n",
       "0         35 affordable things make feel oh-so-fancy\n",
       "1                          would die \"game thrones?\"\n",
       "2  harry sally? john mclaine holly? quiz determin...\n",
       "3  25 times harry styles went way make fans hella...\n",
       "4  penn badgley weighed wild finale \"you\" season ..."
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titles = pd.read_csv('../data/clean_titles.csv')\n",
    "titles.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So I've left the titles still a little bit messy for the purpose of visualization, specifically for the use of `pyLDAvis`. Now we can clean it properly for the sake of our models that will be using the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A preprocess fucntion was already created in the `headline_eda` notebook, this is a modification of that function. We don't need all of the same methods that we used previously because we already have stop words removed, all of the words are tokenized, stemmed, and lowercased. What we're doing now is just making sure everything is lowercased, removing punctuation, replacing multiple spaces with a single space, and removing leading and trailing spaces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(df):\n",
    "    df['clean_title'] = df['clean_title'].str.lower()\n",
    "    df['clean_title'] = df['clean_title'].str.replace('[^a-zA-Z0-9]', ' ') # replace non-alphanumeric characters with spaces\n",
    "    df['clean_title'] = df['clean_title'].str.replace('\\s+', ' ') # replace multiple spaces with a single space\n",
    "    df['clean_title'] = df['clean_title'].str.strip() # remove leading and trailing spaces\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>35 affordable things make feel oh so fancy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>would die game thrones</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>harry sally john mclaine holly quiz determine ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>25 times harry styles went way make fans hella...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>penn badgley weighed wild finale you season 3 ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         clean_title\n",
       "0         35 affordable things make feel oh so fancy\n",
       "1                             would die game thrones\n",
       "2  harry sally john mclaine holly quiz determine ...\n",
       "3  25 times harry styles went way make fans hella...\n",
       "4  penn badgley weighed wild finale you season 3 ..."
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titles = preprocess(titles)\n",
    "titles.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles.to_csv('../data/preprocessed_titles.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import markovify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_model = markovify.NewlineText(titles['clean_title'], state_size=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33 subtly sexist things women like them honestly messed\n",
      "film passing seen cast hawkeye\n",
      "again nick cannon plotting kids time makes zero sense today\n",
      "tbh 30 red carpet moments prove none us allowed watch high school\n"
     ]
    }
   ],
   "source": [
    "for _ in range(4):\n",
    "    print(text_model.make_sentence())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading the github page for `markovify`, the author says that the library works best with large, well-punctuated texts. Maybe I could try and plug in the original data we had before cleaning it in this notebook?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>description</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"In group projects, no boy ever asks for me to...</td>\n",
       "      <td>AAAAAHH!!!View Entire Post ›</td>\n",
       "      <td>33 Subtly Sexist Things Women Deal With That O...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>u/minipenguz\\r\\n\"It goes from reading TO your ...</td>\n",
       "      <td>Literally about to cross-stitch all of these a...</td>\n",
       "      <td>People Are Sharing Their Random Bits Of Life A...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Get all the best moments in pop culture &amp;amp; ...</td>\n",
       "      <td>\"My log does not judge.\"View Entire Post ›</td>\n",
       "      <td>There's A \"Twin Peaks\" Resident In Us All, Whi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"I havent brought it up at all since weve been...</td>\n",
       "      <td>\"I hate that I’m so uncomfortable. I wish I wa...</td>\n",
       "      <td>What Do You Do When Your Identical Twin Starts...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"Last time Queensland went through mandatory i...</td>\n",
       "      <td>\"I'm quitting a job that earns me roughly $140...</td>\n",
       "      <td>In The Wake Of \"The Great Resignation\", Aussie...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             content  \\\n",
       "0  \"In group projects, no boy ever asks for me to...   \n",
       "1  u/minipenguz\\r\\n\"It goes from reading TO your ...   \n",
       "2  Get all the best moments in pop culture &amp; ...   \n",
       "3  \"I havent brought it up at all since weve been...   \n",
       "4  \"Last time Queensland went through mandatory i...   \n",
       "\n",
       "                                         description  \\\n",
       "0                       AAAAAHH!!!View Entire Post ›   \n",
       "1  Literally about to cross-stitch all of these a...   \n",
       "2         \"My log does not judge.\"View Entire Post ›   \n",
       "3  \"I hate that I’m so uncomfortable. I wish I wa...   \n",
       "4  \"I'm quitting a job that earns me roughly $140...   \n",
       "\n",
       "                                               title  \n",
       "0  33 Subtly Sexist Things Women Deal With That O...  \n",
       "1  People Are Sharing Their Random Bits Of Life A...  \n",
       "2  There's A \"Twin Peaks\" Resident In Us All, Whi...  \n",
       "3  What Do You Do When Your Identical Twin Starts...  \n",
       "4  In The Wake Of \"The Great Resignation\", Aussie...  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "headlines_df = pd.read_csv('../data/buzzfeed_headlines.csv')\n",
    "headlines_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "headlines_df = headlines_df[['title']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>33 Subtly Sexist Things Women Deal With That O...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>People Are Sharing Their Random Bits Of Life A...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>There's A \"Twin Peaks\" Resident In Us All, Whi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What Do You Do When Your Identical Twin Starts...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>In The Wake Of \"The Great Resignation\", Aussie...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title\n",
       "0  33 Subtly Sexist Things Women Deal With That O...\n",
       "1  People Are Sharing Their Random Bits Of Life A...\n",
       "2  There's A \"Twin Peaks\" Resident In Us All, Whi...\n",
       "3  What Do You Do When Your Identical Twin Starts...\n",
       "4  In The Wake Of \"The Great Resignation\", Aussie..."
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def detect_lang(txt):\n",
    "    try:\n",
    "        return detect(txt)\n",
    "    except:\n",
    "        return np.nan\n",
    "    \n",
    "headlines_df['language'] = headlines_df.title.apply(detect_lang)\n",
    "headlines_df = headlines_df[headlines_df.language == \"en\"]\n",
    "headlines_df = headlines_df.drop('language', axis=1)\n",
    "headlines_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_2(df):\n",
    "    df['title'] = df['title'].str.lower()\n",
    "    df['title'] = df['title'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop_words)]))\n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>people practice polyamory — rules put place re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>film tv crews, want hear working conditions set</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>billie lourd got super honest generational tra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>i'm sorry, literally 40 things growing up, con...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>could make across survive glass bridge \"squid ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 title\n",
       "198  people practice polyamory — rules put place re...\n",
       "82     film tv crews, want hear working conditions set\n",
       "80   billie lourd got super honest generational tra...\n",
       "188  i'm sorry, literally 40 things growing up, con...\n",
       "111  could make across survive glass bridge \"squid ..."
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_headlines = preprocess_2(headlines_df)\n",
    "clean_headlines.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>jamie lee curtis revealed lindsay lohan secret...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>\"reba\" first aired 20 years ago, here's cast l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341</th>\n",
       "      <td>31 food photos horrific, they'll hurt eyes eve...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>woodworkers get credit deserve, 25 photos prove</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>34 nice things home</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>\"penn badgley hot joe goldberg not\" 26 great t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>335</th>\n",
       "      <td>female ride-share driver, we'd like hear exper...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>329</th>\n",
       "      <td>wanna know dominant personality trait? eat ice...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>90s rom-coms 100% make life better</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>376</th>\n",
       "      <td>32 products fitness-related aches pains</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>24 celebrity couples mega famous, people know ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309</th>\n",
       "      <td>20 wild, lavish, weirdly specific things rich ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>290</th>\n",
       "      <td>50 funniest quotes \"what shadows\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>people sharing worst job interview horror stor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>305</th>\n",
       "      <td>28 men politely turned nerve keep harassing so...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 title\n",
       "107  jamie lee curtis revealed lindsay lohan secret...\n",
       "86   \"reba\" first aired 20 years ago, here's cast l...\n",
       "341  31 food photos horrific, they'll hurt eyes eve...\n",
       "61     woodworkers get credit deserve, 25 photos prove\n",
       "36                                 34 nice things home\n",
       "105  \"penn badgley hot joe goldberg not\" 26 great t...\n",
       "335  female ride-share driver, we'd like hear exper...\n",
       "329  wanna know dominant personality trait? eat ice...\n",
       "270                 90s rom-coms 100% make life better\n",
       "376            32 products fitness-related aches pains\n",
       "45   24 celebrity couples mega famous, people know ...\n",
       "309  20 wild, lavish, weirdly specific things rich ...\n",
       "290                  50 funniest quotes \"what shadows\"\n",
       "9    people sharing worst job interview horror stor...\n",
       "305  28 men politely turned nerve keep harassing so..."
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_headlines.sample(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_model_2 = markovify.Text(headlines_df['title'], state_size=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lauren ridloff made history cfda fashion awards\n",
      "put ranch 13 foods, i'm sorry, literally 40 things growing up, congratulations! officially old\n",
      "rihanna perfectly replicated instagram post gunna halloween 2021 something nutty say\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "for _ in range(4):\n",
    "    print(text_model_2.make_sentence())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nothing really changed after only slightly pre-processing the data. We even get the same results for some headlines. I know the dataset overall isn't large enough to have sufficient training to be able to produce good headlines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c2e5ae9c1fd28b66b6de210cbf9de19d995a279c8eed487e47d02fd4e57b6081"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 64-bit (conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
